"Dependency Taxonomy","From","Dependency","Configuration Parameter A","Component A","Configuration Parameter B(, C and more)","ComponentB","Related description"
"Value Relationship (Numeric)","Hadoop","A >= B","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs","yarn-default.xml","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms","yarn-default.xml","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs is expected to be much greater than yarn.resourcemanager.rm.container-allocation.expiry-interval-ms. Otherwise the behavior is undefined."
"Value Relationship (Numeric)","Hadoop","A <= B","dfs.balancer.getBlocks.min-block-size","hdfs-default.xml","dfs.balancer.getBlocks.size","hdfs-default.xml","Minimum block threshold size in bytes to ignore when fetching a source's block list."
"Value Relationship (Numeric)","Hadoop","A <= B","mapreduce.job.maxtaskfailures.per.tracker","mapred-default.xml","mapreduce.reduce.maxattempts","mapred-default.xml","mapreduce.job.maxtaskfailures.per.tracker MUST be less than mapreduce.map.maxattempts and mapreduce.reduce.maxattempts otherwise the failed task will never be tried on a different node. "
"Value Relationship (Numeric)","Hadoop","A <= B","mapreduce.job.maxtaskfailures.per.tracker","mapred-default.xml","mapreduce.map.maxattempts","mapred-default.xml","mapreduce.job.maxtaskfailures.per.tracker MUST be less than mapreduce.map.maxattempts and mapreduce.reduce.maxattempts otherwise the failed task will never be tried on a different node. "
"Value Relationship (Numeric)","Hadoop","A <= B","dfs.namenode.replication.min","hdfs-default.xml","dfs.namenode.safemode.replication.min","hdfs-default.xml","dfs.namenode.safemode.replication.min This is an expert level setting. Setting this lower than the dfs.namenode.replication.min is not recommend and/or dangerous for production setups."
"Value Relationship (Numeric)","Hadoop","A >= B","dfs.namenode.replication.max-streams-hard-limit","hdfs-default.xml","dfs.namenode.replication.max-streams","hdfs-default.xml","dfs.namenode.replication.max-streams-hard-limit: Hard limit for all replication streams. 
dfs.namenode.replication.max-streams: Hard limit for the number of highest-priority replication streams. "
"Value Relationship (Numeric)","Hadoop","A <= B","mapreduce.map.java.opts","mapred-default.xml","mapreduce.map.memory.mb","mapred-default.xml","mapreduce.map.memory.mb: The amount of memory to request from the scheduler for each map task.
mapreduce.map.java.opts: Java opts only for the child processes that are maps."
"Value Relationship (Numeric)","Hadoop","A >= B + C + D","hbase.lease.recovery.dfs.timeout","hbase-default.xml","dfs.client.socket-timeout; dfs.heartbeat.interval; hbase.lease.recovery.pause","hdfs-default.xml","Should be larger than the sum of dfs.heartbeat.interval, dfs.client.socket-timeout and hbase.lease.recovery.pause"
"Value Relationship (Numeric)","Hadoop","Aâ€™s value is affected by B","yarn.app.attempt.diagnostics.limit.kc","yarn-default.xml","yarn.resourcemanager.state-store.max-completed-applications","yarn-default.xml","yarn.app.attempt.diagnostics.limit.kc defines the limit of the diagnostics message of an application attempt, in kilo characters. In cases where yarn.resourcemanager.state-store.max-completed-applications is set to a large number, it may be desirable to reduce the value of this property to limit the total data stored. "
"Value Relationship (Set)","Hadoop","A and B should be disjointed","dfs.hosts.exclude","hdfs-default.xml","dfs.hosts","hdfs-default.xml","dfs.hosts.exclude: Names a file that contains a list of hosts that are not permitted to connect to the namenode.
dfs.hosts: Names a file that contains a list of hosts that are permitted to connect to the namenode."
"Value Relationship (Set)","Hadoop","A and B should be disjointed","yarn.resourcemanager.nodes.exclude-path","yarn-default.xml","yarn.resourcemanager.nodes.include-path","yarn-default.xml","yarn.resourcemanager.nodes.exclude-path: Path to file with nodes to exclude.
yarn.resourcemanager.nodes.include-path: Path to file with nodes to include."
"Behavioral Dependency","Hadoop","A and B work together","yarn.nodemanager.recovery.enabled","yarn-default.xml","mapreduce.shuffle.port ","mapred-default.xml","When yarn.nodemanager.recovery.enabled is enabled (yarn supports recovery mode), the service should use non-ephemeral ports, which is set by mapreduce.shuffle.port ."
"Behavioral Dependency","Hadoop","A and B work together","hadoop.security.authentication","core-default.xml","dfs.datanode.http.address","hdfs-default.xml","When hadoop.security.authentication is enabled, dfs.datanode.http.address should use privilege ports"
"Behavioral Dependency","Hadoop","A and B work together","hadoop.security.authentication","core-default.xml","dfs.datanode.address","hdfs-default.xml","When hadoop.security.authentication is enabled, dfs.datanode.address should use privilege ports"
"Value Relationship (Numeric)","OpenStack","A >= B","service_down_time","nova","scheduler.periodic_task_interval","nova","if periodic_task_interval is larger than the nova-service 'service_down_time' setting, the computefilter (if enabled) may think the compute service is down."
"Value Relationship (Numeric)","OpenStack","A < B","conductor.send_sensor_data_wait_timeout","ironic","conductor.send_sensor_data_interval","ironic","send_sensor_data_wait_timeout should be less than send_sensor_data_interval value."
"Value Relationship (Numeric)","OpenStack","A <= B","deploy.fast_track_timeout","ironic","api.ramdisk_heartbeat_timeout","ironic","fast_track_timeout should not exceed the [api]ramdisk_heartbeat_timeout setting."
"Value Relationship (Numeric)","OpenStack","A >= B * 2","agent_down_time","neutron","agent.report_interval","neutron","agent_down_time should be at least twice report_interval"
"Value Relationship (Numeric)","OpenStack","A != B","dvr_base_mac","neutron","base_mac","neutron","the 'dvr_base_mac' *must* be different from 'base_mac'"
"Value Relationship (Numeric)","OpenStack","A >= B * C","libvirt.live_migration_completion_timeout","nova","libvirt.live_migration_downtime_steps; libvirt.live_migration_downtime_delay","nova","live_migration_completion_timeout should usually be larger than downtime delay * downtime steps."
"Value Relationship (Numeric)","OpenStack","A == B.substring","serial_console.serialproxy_host","nova","serial_console.base_url","nova","ensure that serialproxy_host is the same ip address which is defined in the option ``base_url``"
"Value Relationship (Numeric)","OpenStack","A == B.substring","serial_console.serialproxy_port","nova","serial_console.base_url","nova","ensure that serialproxy_host is the same port number which is defined in the option ``base_url`` of this section."
"Value Relationship (Numeric)","OpenStack","A > B","object-replicator.http_timeout","swift","object-replicator.node_timeout","swift","http_timeout: Max duration of an http request. This is for REPLICATE finalization calls and so should be longer than node_timeout."
"Value Relationship (Numeric)","OpenStack","A > B","object-reconstructor.http_timeout","swift","object-reconstructor.node_timeout","swift","http_timeout: Max duration of an http request. This is for REPLICATE finalization calls and so should be longer than node_timeout."
"Value Relationship (Numeric)","OpenStack","A >B + C","account-replicator.reclaim_age","swift","account-reaper.delay_reaping; container-updater.interval","swift","The sum of delay_reaping and container-updater.interval interval should be less than the account-replicator reclaim_age."
"Value Relationship (Numeric)","OpenStack","A <= B","proxy-server.concurrency_timeout","swift","proxy-server.conn_timeout","swift","This number (concurrency_timeout) should be between 0 and node_timeout."
"Value Relationship (Numeric)","OpenStack","A >= B","glance.store.swift.store.swift_store_large_object_size","glance","glance.store.swift.store.swift_store_large_object_chunk_size","glance","swift_store_large_object_size: the maximum size, in mb, of the segments when image data is segmented."
"Value Relationship (Numeric)","OpenStack","A <= B","glance.store.swift.store.swift_store_expire_soon_interval","glance","token.expiration","keystone","swift_store_expire_soon_interval: time in seconds defining the size of the window in which a new token may be requested before the current token is due to expire. Hence, by fetching a new token before the current token expiration, we make sure that the token does not expire or is close to expiry before a transaction is attempted."
"Value Relationship (Numeric)","OpenStack","A == B","glance.swift_store_multiple_containers_seed","ironic","glance_store.swift_store_multiple_containers_seed","glance","swift_store_multiple_containers_seed should match a config by the same name in the Glance configuration file."
"Value Relationship (Numeric)","OpenStack","A == B","agent.neutron_agent_poll_interval","ironic","agent.polling_interval","neutron","neutron_agent_poll_interval: the number of seconds neutron agent will wait between polling for device changes. this value should be the same as conf.agent.polling_interval in neutron configuration."
